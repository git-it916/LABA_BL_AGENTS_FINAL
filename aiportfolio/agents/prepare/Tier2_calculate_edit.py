import pandas as pd
import os

# ==========================================================
# 1) S&P500 í”Œë˜ê·¸ ì¶”ê°€ (Ticker + ë‚ ì§œ ë²”ìœ„)
# ==========================================================
def add_sp500_flag(compustat_df: pd.DataFrame, base_path: str) -> pd.DataFrame:
    """
    compustat_df : ìµœì†Œ ['Ticker', 'public_date'] í¬í•¨
    sp500_ticker_start_end.csv : ['Ticker', 'start_date', 'end_date']

    return : compustat_df + sp500 (1 or 0)
    """

    sp500_path = os.path.join(base_path, "sp500_ticker_start_end.csv")
    sp500_df = pd.read_csv(sp500_path)

    # ë‚ ì§œ ë³€í™˜
    sp500_df["start_date"] = pd.to_datetime(sp500_df["start_date"])
    sp500_df["end_date"]   = pd.to_datetime(sp500_df["end_date"])

    # ë¬¸ìì—´ í†µì¼ (ëŒ€ë¬¸ì + strip)
    compustat_df["Ticker"] = compustat_df["Ticker"].astype(str).str.upper().str.strip()
    sp500_df["Ticker"]     = sp500_df["Ticker"].astype(str).str.upper().str.strip()

    # ë§¤ì¹­ ê°€ëŠ¥ì„± ì²´í¬ìš© ë””ë²„ê·¸ (êµì§‘í•© í‹°ì»¤ ê°œìˆ˜)
    comp_tickers = set(compustat_df["Ticker"].unique())
    sp500_tickers = set(sp500_df["Ticker"].unique())
    inter_tickers = comp_tickers & sp500_tickers
    print(f"[DEBUG] Compustat Ticker ìˆ˜ : {len(comp_tickers):,}")
    print(f"[DEBUG] S&P500 Ticker ìˆ˜   : {len(sp500_tickers):,}")
    print(f"[DEBUG] êµì§‘í•© Ticker ìˆ˜   : {len(inter_tickers):,}")

    # merge : Ticker ê¸°ì¤€ (LEFT JOIN â†’ Compustat í–‰ ëˆ„ë½ ì—†ìŒ)
    merged = compustat_df.merge(
        sp500_df,
        on="Ticker",
        how="left"
    )

    # ê³µì‹œì¼ ê¸°ì¤€ìœ¼ë¡œ S&P500 í¸ì… ì—¬ë¶€ í”Œë˜ê·¸
    merged["public_date"] = pd.to_datetime(merged["public_date"])

    merged["sp500"] = (
        (merged["public_date"] >= merged["start_date"]) &
        (merged["public_date"] <= merged["end_date"])
    ).astype(int)

    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
    merged = merged.drop(columns=["start_date", "end_date"])

    # ë¡œê¹…
    print(f"[INFO] S&P500 í”Œë˜ê·¸ ì¶”ê°€ ì™„ë£Œ. ì „ì²´ ê´€ì¸¡ì¹˜ ìˆ˜: {len(merged):,}")
    print(f"[INFO] S&P500 í¸ì… ê´€ì¸¡ì¹˜ ìˆ˜: {merged['sp500'].sum():,}")
    print(f"[INFO] S&P500 í¸ì… ê³ ìœ  ticker ìˆ˜: {merged.loc[merged['sp500'] == 1, 'Ticker'].nunique():,}")

    return merged


# ==========================================================
# 2) GICS ì„¹í„° ë§¤í•‘ (Ticker ê¸°ì¤€ ìµœì‹  datadate 1ê°œ)
# ==========================================================
def add_gics_sector_for_sp500(df: pd.DataFrame, base_path: str):
    """
    df : ìµœì†Œ ['Ticker', 'public_date', 'sp500'] í¬í•¨
    ticker_GICS.csv : ['Ticker', 'datadate', 'gsector']

    ë°˜í™˜:
      df_with_gics : ì „ì²´ DF + gsector
      unmatched_df : sp500 == 1ì¸ë° gsectorê°€ ì—†ëŠ” ê´€ì¸¡ì¹˜ (ë””ë²„ê¹…ìš©, ì €ì¥ì€ ì•ˆ í•¨)
    """

    print(f"[INFO] ì „ì²´ ê´€ì¸¡ì¹˜ ìˆ˜: {len(df):,}")
    print(f"[INFO] ì „ì²´ ê³ ìœ  ticker ìˆ˜: {df['Ticker'].nunique():,}")

    # --- GICS íŒŒì¼ ë¡œë“œ ---
    gics_path = os.path.join(base_path, "ticker_GICS.csv")
    gics = pd.read_csv(gics_path)

    gics["Ticker"]   = gics["Ticker"].astype(str).str.upper().str.strip()
    gics["datadate"] = pd.to_datetime(gics["datadate"])

    # GICS íŒŒì¼ ìì²´ì— ëª‡ ê°œ ì„¹í„°ê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
    print(f"[DEBUG] GICS íŒŒì¼ ë‚´ ê³ ìœ  ì„¹í„° ìˆ˜ (ì „ì²´): {gics['gsector'].nunique()}")
    print(f"[DEBUG] GICS íŒŒì¼ ì„¹í„° ë¶„í¬:\n{gics['gsector'].value_counts().sort_index()}")

    # ê° Tickerë³„ë¡œ ê°€ì¥ ìµœê·¼ datadate 1ê°œë§Œ ë‚¨ê¸°ê¸°
    gics_sorted = gics.sort_values(["Ticker", "datadate"])
    gics_latest = gics_sorted.groupby("Ticker").tail(1).copy()

    print(f"[INFO] GICS ë§¤í•‘ìš© Ticker ìˆ˜: {gics_latest['Ticker'].nunique():,}")
    print(f"[INFO] GICS ë§¤í•‘ìš© ê³ ìœ  ì„¹í„° ìˆ˜: {gics_latest['gsector'].nunique()}")
    print(f"[DEBUG] GICS ìµœì‹  ê¸°ì¤€ ì„¹í„° ë¶„í¬:\n{gics_latest['gsector'].value_counts().sort_index()}")

    # --- Compustat ìª½ë„ Ticker ì •ê·œí™” ---
    df = df.copy()
    df["Ticker"]      = df["Ticker"].astype(str).str.upper().str.strip()
    df["public_date"] = pd.to_datetime(df["public_date"])

    # --- ë‹¨ìˆœ merge: Ticker ê¸°ì¤€ìœ¼ë¡œ gsector ë¶™ì´ê¸° ---
    df_merged = df.merge(
        gics_latest[["Ticker", "gsector"]],
        on="Ticker",
        how="left"
    )

    print(f"[INFO] GICS ë§¤í•‘ í›„ ì „ì²´ ê³ ìœ  ì„¹í„° ìˆ˜ (NaN ì œì™¸): {df_merged['gsector'].nunique(dropna=True)}")

    # --- S&P500 êµ¬ê°„ì—ì„œ ë§¤í•‘ ì„±ê³µ/ì‹¤íŒ¨ ì§‘ê³„ ---
    sp500_mask = df_merged["sp500"] == 1
    sp500_df   = df_merged[sp500_mask].copy()

    total_sp500_rows   = len(sp500_df)
    matched_sp500_rows = sp500_df["gsector"].notna().sum()
    unmatched_sp500    = sp500_df[sp500_df["gsector"].isna()].copy()

    print(f"[INFO] S&P500 ê´€ì¸¡ì¹˜ ìˆ˜: {total_sp500_rows:,}")
    if total_sp500_rows > 0:
        print(f"[INFO] S&P500 + gsector ë§¤í•‘ ì„±ê³µ: {matched_sp500_rows:,} "
              f"({matched_sp500_rows / total_sp500_rows:.2%})")
    else:
        print(f"[INFO] S&P500 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print(f"[INFO] S&P500 + gsector ë§¤í•‘ ì‹¤íŒ¨: {len(unmatched_sp500):,}")
    print(f"[INFO] S&P500 ë‚´ ê³ ìœ  ì„¹í„° ìˆ˜ (ë§¤í•‘ëœ ê²ƒ ê¸°ì¤€): {sp500_df['gsector'].nunique(dropna=True)}")
    print(f"[DEBUG] S&P500 ë‚´ ì„¹í„° ë¶„í¬:\n{sp500_df['gsector'].value_counts(dropna=True).sort_index()}")

    return df_merged, unmatched_sp500


# ==========================================================
# 3) ì„¹í„° Ã— ì—° Ã— ì›”ë³„ í‰ê·  ê³„ì‚°
# ==========================================================
def calculate_sector_monthly_average(df: pd.DataFrame, metric_cols=None) -> pd.DataFrame:
    """
    df : ['Ticker', 'public_date', 'sp500', 'gsector', ...ì§€í‘œë“¤...]
    metric_cols : í‰ê·  ë‚¼ ì§€í‘œ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìˆ«ìí˜•ì—ì„œ ìë™ ì„ íƒ)

    ë°˜í™˜:
      gsector Ã— year Ã— month ë³„ í‰ê·  ì§€í‘œ DF
    """

    df = df.copy()

    # S&P500 + gsector ìˆëŠ” ë°ì´í„°ë§Œ ì‚¬ìš©
    filtered = df[(df["sp500"] == 1) & (df["gsector"].notna())].copy()
    print(f"[INFO] ì„¹í„° í‰ê·  ê³„ì‚° ëŒ€ìƒ ê´€ì¸¡ì¹˜ ìˆ˜: {len(filtered):,}")
    print(f"[INFO] ì„¹í„° í‰ê·  ê³„ì‚° ëŒ€ìƒ ê³ ìœ  ticker ìˆ˜: {filtered['Ticker'].nunique():,}")
    print(f"[INFO] ì„¹í„° í‰ê·  ê³„ì‚° ëŒ€ìƒ ê³ ìœ  ì„¹í„° ìˆ˜: {filtered['gsector'].nunique()}")

    if filtered.empty:
        print("[WARN] ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ DF ë°˜í™˜.")
        return pd.DataFrame()

    filtered["public_date"] = pd.to_datetime(filtered["public_date"])
    filtered["year"]  = filtered["public_date"].dt.year
    filtered["month"] = filtered["public_date"].dt.month

    # metric_colsê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ìˆ«ìí˜• ì»¬ëŸ¼ì—ì„œ ìë™ ì„ íƒ
    if metric_cols is None:
        metric_cols = filtered.select_dtypes(include=["float32", "float64", "int32", "int64"]).columns.tolist()
        metric_cols = [c for c in metric_cols if c not in ["sp500", "year", "month"]]

    print(f"[INFO] í‰ê·  ê³„ì‚° ëŒ€ìƒ ì§€í‘œ ì»¬ëŸ¼: {metric_cols}")

    grouped = (
        filtered
        .groupby(["gsector", "year", "month"])[metric_cols]
        .mean()
        .reset_index()
        .sort_values(["gsector", "year", "month"])
    )

    print(f"[INFO] ì„¹í„°Ã—ì—°Ã—ì›” ì¡°í•© ê°œìˆ˜: {len(grouped):,}")
    print(f"[INFO] ìµœì¢… ê²°ê³¼ ë‚´ ê³ ìœ  ì„¹í„° ìˆ˜: {grouped['gsector'].nunique()}")

    return grouped


# ==========================================================
# MAIN ì‹¤í–‰ë¶€
# ==========================================================
if __name__ == "__main__":

    # Compustat íŒŒì¼ ê²½ë¡œ (OneDrive)
    base_path_compustat = r"C:\Users\shins\OneDrive\ë¬¸ì„œ"

    # ë ˆí¬ì§€í† ë¦¬ ë‚´ database ê²½ë¡œ
    base_path_repo = r"C:\Users\shins\OneDrive\LABA_BL_AGENTS_F\LABA_BL_AGENTS_FINAL\database"

    # ----------------------------------------------
    # 1) Compustat ë¡œë“œ
    # ----------------------------------------------
    comp_path = os.path.join(base_path_compustat, "compustat_2021.01_2024.12_company.csv")
    compustat_df = pd.read_csv(comp_path)
    compustat_df["public_date"] = pd.to_datetime(compustat_df["public_date"])

    # ğŸ”¹ ì—¬ê¸°ì„œ ë¨¼ì € TICKER â†’ Tickerë¡œ í†µì¼
    if "Ticker" not in compustat_df.columns and "TICKER" in compustat_df.columns:
        compustat_df = compustat_df.rename(columns={"TICKER": "Ticker"})

    if "Ticker" not in compustat_df.columns:
        raise ValueError("Compustat íŒŒì¼ì— 'Ticker' ë˜ëŠ” 'TICKER' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í‹°ì»¤ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")

    print(f"[INFO] Compustat ë¡œë“œ ì™„ë£Œ. ê´€ì¸¡ì¹˜ ìˆ˜: {len(compustat_df):,}, "
          f"ê³ ìœ  ticker ìˆ˜: {compustat_df['Ticker'].nunique():,}")

    # ----------------------------------------------
    # 2) S&P500 í”Œë˜ê·¸ ì¶”ê°€
    # ----------------------------------------------
    compustat_df = add_sp500_flag(compustat_df, base_path_repo)

    # ----------------------------------------------
    # 3) GICS ì„¹í„° ë§¤í•‘
    # ----------------------------------------------
    df_with_gics, unmatched = add_gics_sector_for_sp500(compustat_df, base_path_repo)

    # ----------------------------------------------
    # 4) ì„¹í„° Ã— ì—° Ã— ì›” í‰ê·  ê³„ì‚°
    # ----------------------------------------------
    metric_cols = ["bm", "npm", "roe", "roa", "CAPEI", "GProf", "totdebt_invcap"]  # ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ì¡°ì •
    sector_month_avg = calculate_sector_monthly_average(df_with_gics, metric_cols)

    print("\n[RESULT] ì„¹í„° Ã— ì—° Ã— ì›” í‰ê·  (ìƒìœ„ 10í–‰):")
    print(sector_month_avg.head(10))

    # ----------------------------------------------
    # 5) ìµœì¢… ê²°ê³¼ CSVë¡œ ì €ì¥ (database í´ë”)
    # ----------------------------------------------
    output_path = os.path.join(base_path_repo, "sector_monthly_average.csv")
    sector_month_avg.to_csv(output_path, index=False, encoding="utf-8-sig")
    print(f"\n[SAVED] ì„¹í„° Ã— ì—° Ã— ì›” í‰ê·  ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {output_path}")
