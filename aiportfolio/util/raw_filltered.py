import os
import sys
import time
import re
import datetime as dt
from datetime import datetime  # daily_sp500.pyì—ì„œ ì‚¬ìš©
from pathlib import Path
import pandas as pd
import numpy as np
import traceback

# ì‚¬ìš©ë²• ì½ì–´ë³´ì„¸ìš”!! databse í´ë”ì— raw_data.csv íŒŒì¼ì„ ë„£ê³ 
# ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©´ ì „ì²˜ë¦¬ëœ final_processed_stock_data.parquet íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤~
# ë¡œì»¬ì— ì €ì¥í•  í•„ìš”ì—†ìŠµë‹ˆë‹¤.

# python -m aiportfolio.util.raw_filltered

# ##################################################################

def safe_to_csv(df, final_path: str, encoding='utf-8-sig', max_retries=5, wait=0.5):
    """
    OneDrive/Excel ì ê¸ˆ íšŒí”¼ìš© ì•ˆì „ ì €ì¥ í•¨ìˆ˜
    """
    final_path = Path(final_path)
    tmp_path = final_path.with_suffix(final_path.suffix + ".tmp")
    df.to_csv(tmp_path, index=False, encoding=encoding)
    for attempt in range(1, max_retries + 1):
        try:
            os.replace(tmp_path, final_path)
            print(f"âœ“ CSV ì €ì¥ ì™„ë£Œ: {final_path}")
            return
        except PermissionError:
            if attempt == max_retries:
                raise
            time.sleep(wait)

# ##################################################################
# íŒŒì´í”„ë¼ì¸ 1ë²ˆ í•¨ìˆ˜ (daily_NQ_data.py)
# - ìˆ˜ì •: output_file ì €ì¥ ëŒ€ì‹  DataFrameì„ ë°˜í™˜(return)
# ##################################################################

def filter_by_exchange(input_file, column_name, keep_values, columns_to_delete=None):
    """
    CSV/Excel íŒŒì¼ì—ì„œ íŠ¹ì • ì—´ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§í•˜ê³  ë¶ˆí•„ìš”í•œ ì—´ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    (daily_NQ_data.pyì˜ ë©”ì¸ í•¨ìˆ˜)
    
    ìˆ˜ì •:
    - íŒŒì¼ ì €ì¥ ë¡œì§ ì œê±°
    - í•„í„°ë§ëœ DataFrame (df_filtered) ë°˜í™˜
    """
    
    print("=" * 60)
    print("STEP 1: Exchange í•„í„°ë§ (N/Q) ì‹œì‘")
    print("=" * 60)
    
    # 1ë‹¨ê³„: íŒŒì¼ ì½ê¸°
    print(f"\n[1ë‹¨ê³„] íŒŒì¼ ì½ëŠ” ì¤‘: {input_file}")
    if str(input_file).endswith('.csv'):
        df = pd.read_csv(input_file)
    else:
        df = pd.read_excel(input_file)
    initial_count = len(df)
    print(f"âœ“ ì „ì²´ í–‰ ê°œìˆ˜: {initial_count:,}ê°œ")
    
    # 2ë‹¨ê³„: ì—´ í™•ì¸
    print(f"\n[2ë‹¨ê³„] '{column_name}' ì—´ í™•ì¸ ì¤‘...")
    if column_name not in df.columns:
        print(f"âœ— ì˜¤ë¥˜: '{column_name}' ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    print(f"âœ“ '{column_name}' ì—´ ì°¾ìŒ")
    
    # 3ë‹¨ê³„: í•„í„°ë§ ì ìš©
    print(f"\n[3ë‹¨ê³„] í•„í„°ë§ ì ìš© ì¤‘... (ìœ ì§€í•  ê°’: {', '.join(keep_values)})")
    df_filtered = df[df[column_name].isin(keep_values)].copy() # .copy()ë¡œ ì‚¬ë³¸ ìƒì„±
    final_count = len(df_filtered)
    deleted_count = initial_count - final_count
    print(f"âœ“ í•„í„°ë§ ì™„ë£Œ! (ì‚­ì œëœ í–‰: {deleted_count:,}ê°œ, ë‚¨ì€ í–‰: {final_count:,}ê°œ)")
    
    # 4ë‹¨ê³„: ë¶ˆí•„ìš”í•œ ì—´ ì‚­ì œ
    if columns_to_delete:
        print(f"\n[4ë‹¨ê³„] ë¶ˆí•„ìš”í•œ ì—´ ì‚­ì œ ì¤‘...")
        existing_cols_to_delete = [col for col in columns_to_delete if col in df_filtered.columns]
        if existing_cols_to_delete:
            df_filtered = df_filtered.drop(columns=existing_cols_to_delete)
            print(f"  ì‚­ì œëœ ì—´: {', '.join(existing_cols_to_delete)}")
    
    # --- ì‹œì´ ê³„ì‚° ë¡œì§ (ë³„ë„ íŒŒì¼ë¡œ ì €ì¥) ---
    if "DlyCap" in df_filtered.columns and "DlyCalDt" in df_filtered.columns:
        print(f"\n[ë³„ë„ ì‘ì—…] ë‚ ì§œë³„(N/Q) ì‹œì´ ë° ë¹„ìœ¨ ê³„ì‚° ì¤‘...")
        df_filtered["DlyCalDt"] = pd.to_datetime(df_filtered["DlyCalDt"])
        pivot = (
            df_filtered
            .groupby(["DlyCalDt", column_name], as_index=False)["DlyCap"]
            .sum()
            .pivot(index="DlyCalDt", columns=column_name, values="DlyCap")
            .fillna(0.0)
        )
        pivot = pivot.rename(columns={"N": "mcap_N", "Q": "mcap_Q"})
        if "mcap_N" not in pivot.columns: pivot["mcap_N"] = 0.0
        if "mcap_Q" not in pivot.columns: pivot["mcap_Q"] = 0.0
        pivot["total_mcap"] = pivot["mcap_N"] + pivot["mcap_Q"]
        pivot["ratio_N"] = np.where(pivot["total_mcap"] > 0, pivot["mcap_N"] / pivot["total_mcap"], 0.0)
        pivot["ratio_Q"] = np.where(pivot["total_mcap"] > 0, pivot["mcap_Q"] / pivot["total_mcap"], 0.0)

        db_dir = Path.cwd() / "database"
        db_dir.mkdir(exist_ok=True)
        out_csv_path = db_dir / "mcap_by_exchange_daily.csv"
        pivot.reset_index().to_csv(out_csv_path, index=False, encoding="utf-8-sig")
        print(f"âœ“ ë‚ ì§œë³„(N/Q) ì‹œì´ ë¹„ìœ¨ íŒŒì¼ ì €ì¥: {out_csv_path}")
    
    print(f"\nâœ… STEP 1 ì™„ë£Œ (filter_by_exchange)")
    
    # 5ë‹¨ê³„: ê²°ê³¼ DataFrame ë°˜í™˜
    return df_filtered


# ##################################################################
# íŒŒì´í”„ë¼ì¸ 2ë²ˆ í•¨ìˆ˜ (daily_sp500.py)
# - ìˆ˜ì •: filtered_file (ê²½ë¡œ) ëŒ€ì‹  input_df (DataFrame)ì„ ì…ë ¥ë°›ìŒ
# - ìˆ˜ì •: output_file ì €ì¥ ëŒ€ì‹  DataFrameì„ ë°˜í™˜(return)
# ##################################################################

def match_sp500_by_date(input_df, sp500_file, 
                        ticker_column='Ticker', date_column='DlyCalDt'):
    """
    í•„í„°ë§ëœ DataFrameì˜ tickerì™€ ë‚ ì§œë¥¼ SP500 ê¸°ê°„ë³„ ë¦¬ìŠ¤íŠ¸ì™€ ë§¤ì¹­í•©ë‹ˆë‹¤.
    (daily_sp500.pyì˜ ë©”ì¸ í•¨ìˆ˜)
    
    ìˆ˜ì •:
    - input_df (DataFrame)ì„ ì…ë ¥ ë°›ìŒ
    - íŒŒì¼ ì €ì¥ ë¡œì§ ì œê±°
    - 'sp500' ì—´ì´ ì¶”ê°€ëœ DataFrame ë°˜í™˜
    """
    
    print("=" * 70)
    print("STEP 2: SP500 ê¸°ê°„ë³„ ë§¤ì¹­ ì‹œì‘")
    print("=" * 70)
    
    # 1ë‹¨ê³„: ì…ë ¥ DataFrame ì‚¬ìš©
    df_filtered = input_df.copy() # ì›ë³¸ ë³´ì¡´ì„ ìœ„í•´ ì‚¬ë³¸ ì‚¬ìš©
    total_records = len(df_filtered)
    print(f"\n[1ë‹¨ê³„] ì…ë ¥ DataFrame ì‚¬ìš© (ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {total_records:,}ê°œ)")
    
    # ì—´ í™•ì¸
    if ticker_column not in df_filtered.columns:
        print(f"\nâœ— ì˜¤ë¥˜: '{ticker_column}' ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    if date_column not in df_filtered.columns:
        print(f"\nâœ— ì˜¤ë¥˜: '{date_column}' ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    
    # 2ë‹¨ê³„: SP500 ê¸°ê°„ íŒŒì¼ ì½ê¸°
    print(f"\n[2ë‹¨ê³„] SP500 ê¸°ê°„ íŒŒì¼ ì½ëŠ” ì¤‘: {sp500_file}")
    df_sp500 = pd.read_csv(sp500_file)
    print(f"âœ“ SP500 ê¸°ê°„ ë ˆì½”ë“œ ìˆ˜: {len(df_sp500):,}ê°œ")
    
    # 3ë‹¨ê³„: ë‚ ì§œ ë³€í™˜
    print(f"\n[3ë‹¨ê³„] ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì¤‘...")
    df_filtered[date_column] = pd.to_datetime(df_filtered[date_column])
    df_sp500['start_date'] = pd.to_datetime(df_sp500['start_date'])
    df_sp500['end_date'] = df_sp500['end_date'].fillna('2099-12-31')
    df_sp500['end_date'] = pd.to_datetime(df_sp500['end_date'])
    print(f"âœ“ ë‚ ì§œ ë³€í™˜ ì™„ë£Œ")
    
    # Ticker ëŒ€ë¬¸ì í†µì¼
    df_filtered['ticker_upper'] = df_filtered[ticker_column].astype(str).str.strip().str.upper()
    df_sp500['ticker_upper'] = df_sp500['Ticker'].astype(str).str.strip().str.upper()
    
    # 4ë‹¨ê³„: ë§¤ì¹­ ìˆ˜í–‰
    print(f"\n[4ë‹¨ê³„] ê¸°ê°„ë³„ ë§¤ì¹­ ì§„í–‰ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    sp500_flags = []
    batch_size = 10000
    total_batches = (total_records + batch_size - 1) // batch_size
    
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min((batch_num + 1) * batch_size, total_records)
        
        batch_flags = []
        for idx in range(start_idx, end_idx):
            row = df_filtered.iloc[idx]
            ticker = row['ticker_upper']
            date = row[date_column]
            sp500_periods = df_sp500[df_sp500['ticker_upper'] == ticker]
            is_in_sp500 = False
            for _, period in sp500_periods.iterrows():
                if period['start_date'] <= date <= period['end_date']:
                    is_in_sp500 = True
                    break
            batch_flags.append(1 if is_in_sp500 else 0)
        
        sp500_flags.extend(batch_flags)
        
        if (batch_num + 1) % 10 == 0 or batch_num == total_batches - 1:
            progress = ((batch_num + 1) / total_batches) * 100
            processed = min((batch_num + 1) * batch_size, total_records)
            print(f"  ì§„í–‰: {processed:,}/{total_records:,} ({progress:.1f}%)")
    
    df_filtered['sp500'] = sp500_flags
    df_filtered = df_filtered.drop(columns=['ticker_upper'])
    
    sp500_matched = df_filtered['sp500'].sum()
    match_rate = (sp500_matched / total_records * 100) if total_records > 0 else 0
    print(f"\nâœ“ ë§¤ì¹­ ì™„ë£Œ! (SP500 í¬í•¨: {sp500_matched:,}ê°œ, {match_rate:.1f}%)")
    
    # 5ë‹¨ê³„: (ì €ì¥ ëŒ€ì‹ ) DataFrame ë°˜í™˜
    print(f"\nâœ… STEP 2 ì™„ë£Œ (match_sp500_by_date)! 'sp500' ì—´ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return df_filtered


# ##################################################################
# íŒŒì´í”„ë¼ì¸ 3ë²ˆ í•¨ìˆ˜ (daily_GICS.py)
# - ìˆ˜ì •: input_file (ê²½ë¡œ) ëŒ€ì‹  input_df (DataFrame)ì„ ì…ë ¥ë°›ìŒ
# - ìˆ˜ì •: output_file ì €ì¥ ëŒ€ì‹  DataFrameì„ ë°˜í™˜(return)
# ##################################################################

def match_gics_sector(input_df, gics_file, ticker_column='Ticker'):
    """
    ì…ë ¥ DataFrameì˜ tickerì™€ GICS íŒŒì¼ì˜ gsectorë¥¼ ë§¤ì¹­í•©ë‹ˆë‹¤.
    (daily_GICS.pyì˜ ë©”ì¸ í•¨ìˆ˜)
    
    ìˆ˜ì •:
    - input_df (DataFrame)ì„ ì…ë ¥ ë°›ìŒ
    - ì¤‘ê°„/ìµœì¢… íŒŒì¼ ì €ì¥ ë¡œì§ ì œê±°
    - 'gsector'ê°€ ì¶”ê°€/ì •ë¦¬ëœ ìµœì¢… DataFrame ë°˜í™˜
    """
    print("=" * 70)
    print("STEP 3: GICS Sector ë§¤ì¹­ ì‹œì‘")
    print("=" * 70)

    # 1ë‹¨ê³„: ì…ë ¥ DataFrame ì‚¬ìš©
    df_input = input_df.copy() # ì›ë³¸ ë³´ì¡´ì„ ìœ„í•´ ì‚¬ë³¸ ì‚¬ìš©
    total_records = len(df_input)
    print(f"\n[1ë‹¨ê³„] ì…ë ¥ DataFrame ì‚¬ìš© (ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {total_records:,}ê°œ)")

    # Ticker ì—´ í™•ì¸
    if ticker_column not in df_input.columns:
        print(f"\nâœ— ì˜¤ë¥˜: '{ticker_column}' ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    
    # 2ë‹¨ê³„: GICS íŒŒì¼ ì½ê¸°
    print(f"\n[2ë‹¨ê³„] GICS íŒŒì¼ ì½ëŠ” ì¤‘: {gics_file}")
    df_gics = pd.read_csv(gics_file)
    print(f"âœ“ GICS ë ˆì½”ë“œ ìˆ˜: {len(df_gics):,}ê°œ")

    # GICS íŒŒì¼ì˜ ì—´ í™•ì¸
    gics_ticker_col = None
    gics_sector_col = None
    for col in df_gics.columns:
        if col.lower() in ['ticker', 'symbol']: gics_ticker_col = col; break
    for col in df_gics.columns:
        if 'sector' in col.lower() or col.lower() == 'gsector': gics_sector_col = col; break
    if gics_ticker_col is None: print(f"\nâœ— ì˜¤ë¥˜: GICS íŒŒì¼ì—ì„œ ticker ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    if gics_sector_col is None: print(f"\nâœ— ì˜¤ë¥˜: GICS íŒŒì¼ì—ì„œ sector ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return None
    print(f"\nâœ“ GICS Ticker ì—´: '{gics_ticker_col}', Sector ì—´: '{gics_sector_col}'")

    # 3ë‹¨ê³„: GICS ë°ì´í„° ì¤€ë¹„
    print(f"\n[3ë‹¨ê³„] GICS ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì¤‘...")
    df_gics['ticker_upper'] = df_gics[gics_ticker_col].astype(str).str.strip().str.upper()
    gics_dict = df_gics.set_index('ticker_upper')[gics_sector_col].to_dict()
    print(f"âœ“ GICS ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ: {len(gics_dict):,}ê°œ")
    
    # 4ë‹¨ê³„: ë§¤ì¹­ ìˆ˜í–‰
    print(f"\n[4ë‹¨ê³„] Sector ë§¤ì¹­ ì¤‘...")
    df_input['ticker_upper'] = df_input[ticker_column].astype(str).str.strip().str.upper()
    df_input['gsector'] = df_input['ticker_upper'].map(gics_dict)
    df_input = df_input.drop(columns=['ticker_upper'])

    matched_count = df_input['gsector'].notna().sum()
    match_rate = (matched_count / total_records * 100) if total_records > 0 else 0
    print(f"âœ“ ë§¤ì¹­ ì™„ë£Œ! (ë§¤ì¹­ ì„±ê³µ: {matched_count:,}ê°œ, {match_rate:.1f}%)")

    # 5ë‹¨ê³„: SP500 ì²´í¬(ì„ íƒ)
    if 'sp500' in df_input.columns:
        sp500_no_gics_count = len(df_input[(df_input['sp500'] == 1) & (df_input['gsector'].isna())])
        if sp500_no_gics_count > 0:
            print(f"  âš  SP500 ì¢…ëª© ì¤‘ GICSê°€ ì—†ëŠ” ë ˆì½”ë“œ: {sp500_no_gics_count}ê°œ")
        else:
            print(f"  âœ“ SP500 ì¢…ëª©ì€ ëª¨ë‘ GICSê°€ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # 6ë‹¨ê³„: ìˆ˜ë™ ë³´ì • ë° GICS ì—†ëŠ” í–‰ ì‚­ì œ
    print(f"\n[6ë‹¨ê³„] ë°ì´í„° ì •ë¦¬ (GOOG ë³´ì •, GICS ì—†ëŠ” í–‰ ì‚­ì œ)")
    goog_mask = df_input[ticker_column].astype(str).str.upper() == 'GOOG'
    if goog_mask.sum() > 0:
        df_input.loc[goog_mask, 'gsector'] = 50.0
        print(f"  âœ“ GOOGì˜ gsectorë¥¼ 50.0ìœ¼ë¡œ ì„¤ì •")

    before_delete = len(df_input)
    df_input = df_input[df_input['gsector'].notna()]
    after_delete = len(df_input)
    deleted_count = before_delete - after_delete
    print(f"  âœ“ GICS ì—†ëŠ” í–‰ ì‚­ì œ ì™„ë£Œ (ì‚­ì œëœ í–‰: {deleted_count:,}ê°œ)")

    # 7ë‹¨ê³„: (ì €ì¥ ëŒ€ì‹ ) DataFrame ë°˜í™˜
    print(f"\nâœ… STEP 3 ì™„ë£Œ (match_gics_sector)!")
    print(f"  ìµœì¢… ë ˆì½”ë“œ ìˆ˜: {after_delete:,}ê°œ")
    
    return df_input

# ##################################################################
# ë…ë¦½ í•¨ìˆ˜ (open_DTB3.py)
# - (ì´ íŒŒì´í”„ë¼ì¸ê³¼ ë³„ë„ë¡œ RF ê¸ˆë¦¬ ë¡œë“œ ì‹œ ì‚¬ìš©)
# ##################################################################

def open_rf_rate(file_path="database/DTB3.csv"):
    """
    ë¬´ìœ„í—˜ ì´ììœ¨(DTB3.csv) íŒŒì¼ì„ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    (open_DTB3.pyì˜ ë©”ì¸ í•¨ìˆ˜)
    """
    file_path = Path(file_path)
    if not file_path.exists():
        print(f"ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    try:
        df = pd.read_csv(file_path)
        print(f"âœ“ ë¬´ìœ„í—˜ ì´ììœ¨ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {file_path}")
        return df
    except Exception as e:
        print(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# ##################################################################
# ğŸš€ ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
# ##################################################################

def main_pipeline():
    """
    ë°ì´í„° ì „ì²˜ë¦¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Input: database/raw_data.csv
    Output: database/final_processed_stock_data.parquet
    """
    print("======= ğŸš€ RAW DATA FILTERING PIPELINE START ğŸš€ =======")
    
    # --- 1. ê²½ë¡œ ì„¤ì • ---
    # (ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 'database' í´ë” ì°¸ì¡°)
    try:
        DB_PATH = Path.cwd() / "database"
        DB_PATH.mkdir(exist_ok=True) # database í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    except Exception as e:
        print(f"âœ— 'database' í´ë” ê²½ë¡œ ì„¤ì • ì˜¤ë¥˜: {e}")
        return

    # --- ì…ë ¥ íŒŒì¼ (ì‚¬ìš©ì ìš”ì²­) ---
    raw_data_file = DB_PATH / "raw_data.csv"
    
    # --- ì°¸ì¡°(Lookup) íŒŒì¼ ---
    # (ì´ íŒŒì¼ë“¤ì€ 'database' í´ë”ì— ë¯¸ë¦¬ ì¤€ë¹„ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)
    sp500_list_file = DB_PATH / "sp500_ticker_start_end.csv"
    gics_list_file = DB_PATH / "ticker_GICS.csv"
    
    # --- ìµœì¢… ì¶œë ¥ íŒŒì¼ (ì‚¬ìš©ì ìš”ì²­) ---
    final_output_parquet = DB_PATH / "final_processed_stock_data.parquet"

    # --- íŒŒì´í”„ë¼ì¸ 1 ë§¤ê°œë³€ìˆ˜ ---
    filter_column = "PrimaryExch"
    filter_keep_values = ['N', 'Q']
    filter_delete_columns = ['PERMNO', 'HdrCUSIP', 'PERMCO', 'vwretd']

    # --- íŒŒì´í”„ë¼ì¸ 2/3 ë§¤ê°œë³€ìˆ˜ ---
    ticker_column = "Ticker"
    date_column = "DlyCalDt"
    
    
    # --- íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ---
    if not raw_data_file.exists():
        print(f"âœ—âœ—âœ— íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: ì…ë ¥ íŒŒì¼ '{raw_data_file.name}'ì„ 'database' í´ë”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not sp500_list_file.exists():
        print(f"âœ—âœ—âœ— íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: ì°¸ì¡° íŒŒì¼ '{sp500_list_file.name}'ì„ 'database' í´ë”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not gics_list_file.exists():
        print(f"âœ—âœ—âœ— íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: ì°¸ì¡° íŒŒì¼ '{gics_list_file.name}'ì„ 'database' í´ë”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        # --- ğŸš€ [STEP 1: NQ í•„í„°ë§] ---
        # Input: raw_data.csv
        # Output: df_step1 (DataFrame)
        df_step1 = filter_by_exchange(
            input_file=str(raw_data_file),
            column_name=filter_column,
            keep_values=filter_keep_values,
            columns_to_delete=filter_delete_columns
        )
        if df_step1 is None: raise Exception("STEP 1 (NQ í•„í„°ë§) ì‹¤íŒ¨")

        # --- ğŸš€ [STEP 2: SP500 ê¸°ê°„ ë§¤ì¹­] ---
        # Input: df_step1 (DataFrame)
        # Output: df_step2 (DataFrame)
        df_step2 = match_sp500_by_date(
            input_df=df_step1,
            sp500_file=str(sp500_list_file),
            ticker_column=ticker_column,
            date_column=date_column
        )
        if df_step2 is None: raise Exception("STEP 2 (SP500 ë§¤ì¹­) ì‹¤íŒ¨")

        # --- ğŸš€ [STEP 3: GICS Sector ë§¤ì¹­] ---
        # Input: df_step2 (DataFrame)
        # Output: df_step3 (DataFrame)
        df_step3 = match_gics_sector(
            input_df=df_step2,
            gics_file=str(gics_list_file),
            ticker_column=ticker_column
        )
        if df_step3 is None: raise Exception("STEP 3 (GICS ë§¤ì¹­) ì‹¤íŒ¨")
        
        # --- ğŸš€ [STEP 4: ìµœì¢… Parquet íŒŒì¼ ì €ì¥] ---
        print("\n" + "="*70)
        print("ğŸš€ STEP 4: ìµœì¢… Parquet íŒŒì¼ ì €ì¥")
        print("="*70)
        df_step3.to_parquet(final_output_parquet, index=False, engine='pyarrow')
        print(f"âœ“ ìµœì¢… Parquet íŒŒì¼ ì €ì¥ ì™„ë£Œ: {final_output_parquet}")
        
        print("\n" + "="*70)
        print("======= âœ… PIPELINE ALL COMPLETE âœ… =======")
        print(f"  ìµœì¢… ë ˆì½”ë“œ ìˆ˜: {len(df_step3):,}ê°œ")
        print(f"  ìµœì¢… íŒŒì¼: {final_output_parquet.name}")
        print("="*70)

    except FileNotFoundError as e:
        print(f"\nâœ—âœ—âœ— íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"  {e}")
    except PermissionError as e:
        print(f"\nâœ—âœ—âœ— íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: ê¶Œí•œ(ì ê¸ˆ) ì˜¤ë¥˜ì…ë‹ˆë‹¤. íŒŒì¼ì´ ì—´ë ¤ìˆëŠ”ì§€/ë™ê¸°í™” ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print(f"  {e}")
    except Exception as e:
        print(f"\nâœ—âœ—âœ— íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨: ì˜¤ë¥˜ ë°œìƒ")
        print(f"  {e}")
        traceback.print_exc()

if __name__ == "__main__":
    # ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ë©´ ë©”ì¸ íŒŒì´í”„ë¼ì¸ ê°€ë™
    main_pipeline()